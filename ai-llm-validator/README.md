# ğŸ›¡ï¸ AI LLM Validator â€” Hallucination & Bias Detection System

A **production-grade, modular Python system** that evaluates Large Language Model outputs for **factual consistency** (hallucination detection), **bias risk**, and overall **trustworthiness** (0â€“100 trust score).

---

## ğŸ“‹ Table of Contents

1. [Problem Statement](#problem-statement)  
2. [Architecture](#architecture)  
3. [Project Structure](#project-structure)  
4. [Setup Instructions](#setup-instructions)  
5. [How to Run](#how-to-run)  
6. [Example Output](#example-output)  
7. [Evaluation](#evaluation)  
8. [Limitations](#limitations)  
9. [Future Scope](#future-scope)  

---

 Problem Statement

Large Language Models (GPT-4, Claude, Llama, etc.) can generate fluent, convincing text that contains **factual errors** (hallucinations) or **biased framing**.  When these outputs reach end-users without verification, trust erodes and real harm can followâ€”especially in healthcare, legal, and educational applications.

**AI LLM Validator** is a **post-generation verification layer** that sits between the LLM and the user.  It:

- Extracts atomic factual claims from the LLM's response.
- Retrieves evidence from a knowledge base using semantic search.
- Verifies each claim via Natural Language Inference.
- Detects bias through hybrid ML + rule-based analysis.
- Aggregates everything into a transparent **Trust Score (0â€“100)**.

---

## ğŸ—ï¸ Architecture

```
User Question
      â”‚
      â–¼
LLM Output (pasted / API)
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Claim Extraction      â”‚  â† spaCy NER + sentence segmentation
â”‚   (claim_extractor.py)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Evidence Retrieval    â”‚  â† FAISS + Sentence-BERT embeddings
â”‚   (retriever.py)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NLI Verification      â”‚  â† RoBERTa-MNLI (entail / contradict / neutral)
â”‚   (nli_checker.py)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Bias Analysis         â”‚  â† Sentiment (DistilBERT) + Keyword heuristics
â”‚   (bias_analyzer.py)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Trust Score           â”‚  â† Weighted aggregation (0â€“100)
â”‚   (trust_scorer.py)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit Dashboard   â”‚  â† Interactive UI
â”‚   (app/app.py)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
ai-llm-validator/
â”‚
â”œâ”€â”€ app/                        # Streamlit UI layer
â”‚   â”œâ”€â”€ app.py                  # Main dashboard entry point
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ score_display.py    # Trust score visualisation
â”‚       â”œâ”€â”€ evidence_panel.py   # Per-claim evidence accordion
â”‚       â””â”€â”€ bias_meter.py       # Bias score + risk display
â”‚
â”œâ”€â”€ core/                       # Core business logic
â”‚   â”œâ”€â”€ claim_extractor.py      # spaCy-based claim extraction
â”‚   â”œâ”€â”€ retriever.py            # FAISS evidence retrieval
â”‚   â”œâ”€â”€ nli_checker.py          # RoBERTa-MNLI NLI verification
â”‚   â”œâ”€â”€ bias_analyzer.py        # Hybrid bias detection
â”‚   â”œâ”€â”€ trust_scorer.py         # Weighted score aggregation
â”‚   â””â”€â”€ pipeline.py             # End-to-end orchestrator
â”‚
â”œâ”€â”€ models/                     # Model wrappers (lazy-load, cached)
â”‚   â”œâ”€â”€ embedding_model.py      # Sentence-BERT wrapper
â”‚   â”œâ”€â”€ nli_model.py            # RoBERTa-MNLI wrapper
â”‚   â””â”€â”€ bias_model.py           # DistilBERT sentiment wrapper
â”‚
â”œâ”€â”€ data/                       # Sample data & knowledge base
â”‚   â”œâ”€â”€ sample_knowledge_base.json
â”‚   â”œâ”€â”€ fever_samples.json
â”‚   â””â”€â”€ test_cases.json
â”‚
â”œâ”€â”€ evaluation/                 # Evaluation & metrics
â”‚   â”œâ”€â”€ metrics.py              # Precision / Recall / F1
â”‚   â”œâ”€â”€ evaluate.py             # Evaluation runner
â”‚   â””â”€â”€ results/                # Auto-generated results
â”‚
â”œâ”€â”€ utils/                      # Shared utilities
â”‚   â”œâ”€â”€ config.py               # Centralised configuration
â”‚   â”œâ”€â”€ logger.py               # Logging setup
â”‚   â””â”€â”€ helpers.py              # JSON I/O, timers, etc.
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ main.py                     # CLI entry point
```

---

## âš™ï¸ Setup Instructions

### Prerequisites

- **Python 3.10+**
- **pip** (or conda)
- ~2 GB disk space for pretrained models (downloaded on first run)

### 1. Clone / Copy the Project

```bash
cd ai-llm-validator
```

### 2. Create a Virtual Environment (recommended)

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS / Linux
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Download the spaCy Language Model

```bash
python -m spacy download en_core_web_sm
```

### 5. (Optional) Verify Installation

```bash
python -c "import torch, transformers, sentence_transformers, faiss, spacy, streamlit; print('All imports OK')"
```

---

## ğŸš€ How to Run

### CLI â€” Quick Demo Validation

```bash
python main.py validate
```

Runs a hard-coded demo question + answer through the full pipeline and prints the Trust Score, per-claim verdicts, and bias analysis to the terminal.

### CLI â€” Full Evaluation Suite

```bash
python main.py evaluate
```

Loads all test cases from `data/test_cases.json`, runs each through the pipeline, computes Precision / Recall / F1, and saves results to `evaluation/results/evaluation_results.json`.

### Streamlit Dashboard

```bash
streamlit run app/app.py
```

Opens an interactive web UI where you can paste any question + LLM output and get a visual trust report.

---

## ğŸ“Š Example Output

### Trust Score

```
  Trust Score : 78.5 / 100  (Trusted)
  Factual     : 0.872
  Evidence    : 0.681
  Bias        : 0.043
  Time        : 3.21s
```

### Per-Claim Verification

```
  Claim 1: [    entailment] score=0.91  The Eiffel Tower is located in Paris, France.
  Claim 2: [    entailment] score=0.87  It was constructed in 1889.
  Claim 3: [       neutral] score=0.54  The tower was designed by Gustave Eiffel's company.
```

### Bias Analysis

```
  Bias Risk : Low  (score=0.043)
  No significant bias signals detected. Overall risk level: Low.
```

---

## ğŸ“ˆ Evaluation

The evaluation module uses FEVER-style test cases with known ground-truth labels (`"high"` = trustworthy, `"low"` = untrustworthy).

Metrics computed:
- **Precision** â€” Of all outputs labelled trustworthy, how many truly are?
- **Recall** â€” Of all truly trustworthy outputs, how many did we catch?
- **F1 Score** â€” Harmonic mean of precision and recall.
- **Accuracy** â€” Overall classification correctness.

Results are saved to `evaluation/results/evaluation_results.json`.

---

## âš ï¸ Limitations

| Area | Limitation |
|------|-----------|
| **Knowledge Base** | Small sample KB (20 entries); production use needs a large, up-to-date corpus. |
| **Claim Extraction** | Heuristic sentence-level splitting; does not handle multi-sentence claims or implicit claims. |
| **NLI Model** | RoBERTa-MNLI may struggle with highly technical or domain-specific language. |
| **Bias Detection** | Keyword lists are not exhaustive; sentiment model was trained on movie reviews. |
| **Latency** | Running three transformer models sequentially on CPU can take 5â€“15 s per validation. |
| **Coverage** | Only English is supported. |

---

## ğŸ”® Future Scope

- **Live knowledge retrieval** â€” Integrate a web search API (e.g., Google, Bing) for real-time evidence.
- **Learned claim classifier** â€” Replace the heuristic confidence score with a fine-tuned model that distinguishes facts vs. opinions.
- **GPU acceleration** â€” Enable CUDA batching for <1 s latency.
- **Multi-language support** â€” Use multilingual Sentence-BERT and MNLI models.
- **User feedback loop** â€” Let users flag incorrect verdicts to improve the system over time.
- **API layer** â€” Expose the pipeline via FastAPI for programmatic integration.
- **Larger knowledge bases** â€” Use FAISS IVF or HNSW indexes for million-scale passage retrieval.
- **Toxicity model upgrade** â€” Replace keyword matching with Perspective API or a dedicated toxicity classifier.

---

## ğŸ“„ License

This project is provided for educational and research purposes.

---

*Built with â¤ï¸ using Python, HuggingFace Transformers, Sentence-BERT, FAISS, spaCy, and Streamlit.*
