"""
app.py â€” Streamlit dashboard for the AI LLM Validator.

Launch with:
    streamlit run app/app.py

The UI collects a user question and an LLM-generated answer, runs the
full validation pipeline, and displays:
    â€¢ Trust Score (large number + rating)
    â€¢ Factual consistency breakdown
    â€¢ Evidence panel (per-claim)
    â€¢ Bias analysis meter

All display logic is delegated to dedicated components under
``app/components/``.  No core ML logic lives in this file.
"""

import sys
from pathlib import Path

# â”€â”€ Make project root importable â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_PROJECT_ROOT = Path(__file__).resolve().parent.parent
if str(_PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(_PROJECT_ROOT))

import streamlit as st

from app.components.bias_meter import render_bias_meter
from app.components.evidence_panel import render_evidence_panel
from app.components.score_display import render_trust_score
from core.pipeline import ValidationPipeline

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Page Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="AI LLM Validator",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sidebar â€” Project Info
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.title("ğŸ›¡ï¸ AI LLM Validator")
    st.markdown(
        """
        **Hallucination & Bias Detection System**

        This tool audits LLM-generated responses for:
        - âœ… Factual consistency
        - âš–ï¸ Bias risk
        - ğŸ… Overall trustworthiness

        ---
        *Pipeline:* Claim Extraction â†’ Evidence Retrieval (FAISS + SBERT)
        â†’ NLI Verification (RoBERTa-MNLI) â†’ Bias Analysis â†’ Trust Score
        """
    )
    st.markdown("---")
    st.caption("Built with Streamlit Â· HuggingFace Â· FAISS")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Pipeline Singleton (cached so models load once)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner="Loading AI models â€” this may take a minute on first runâ€¦")
def get_pipeline() -> ValidationPipeline:
    """Instantiate and cache the validation pipeline."""
    return ValidationPipeline()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main Content
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ” LLM Output Validator")
st.markdown(
    "Enter a user question and the LLM's response below, then click "
    "**Validate Output** to run the full verification pipeline."
)

# --- Input fields ---
user_question = st.text_input(
    "User Question",
    placeholder="e.g., Where is the Eiffel Tower?",
)

llm_output = st.text_area(
    "LLM Output",
    height=180,
    placeholder="Paste the LLM-generated answer hereâ€¦",
)

# --- Validate button ---
validate_clicked = st.button("ğŸš€ Validate Output", type="primary", use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Validation Flow
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if validate_clicked:
    if not user_question.strip() or not llm_output.strip():
        st.warning("Please fill in both the user question and the LLM output.")
    else:
        pipeline = get_pipeline()

        with st.spinner("Running validation pipelineâ€¦"):
            report = pipeline.validate(user_question, llm_output)

        st.success(
            f"Validation complete in **{report['inference_time_s']:.2f}s**."
        )

        # ---- Trust Score ----
        st.markdown("---")
        render_trust_score(report["trust_result"])

        # ---- Evidence Panel ----
        st.markdown("---")
        render_evidence_panel(report["claims"], report["claim_results"])

        # ---- Bias Meter ----
        st.markdown("---")
        render_bias_meter(report["bias_result"])

        # ---- Raw Report (expandable) ----
        with st.expander("ğŸ“„ Full Validation Report (JSON)"):
            st.json(report)
